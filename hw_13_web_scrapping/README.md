# Парсинг новинного сайту для отримання останніх новин
Вам потрібно створити Python-скрипт, який буде парсити головну сторінку новинного сайту та збирати інформацію про останні новини. 
Ваш скрипт повинен отримувати заголовки новин, посилання на повний текст новини, дату публікації та короткий опис (якщо він присутній на сторінці).

## Технічні вимоги:
Використання бібліотек:
Використайте бібліотеки requests для завантаження HTML-коду сторінки та BeautifulSoup для парсингу HTML.
Для додаткової обробки отриманих даних (опціонально) можна використовувати pandas.
2. Цільова сторінка:

Виберіть будь-який новинний сайт, який має простий HTML-код та не вимагає авторизації для доступу до новин.
Наприклад, https://example.com/news (замість цього потрібно вибрати сайт, який підтримує основи HTML).
3. Інформація для збору:

Заголовок кожної новини.
Посилання на сторінку з повним текстом новини.
Дата публікації.
Короткий опис або анотація новини (якщо є).
4. Реалізація функцій:

get_page(url): завантажує HTML-код сторінки за вказаною URL та повертає BeautifulSoup-об'єкт.
parse_news(soup): отримує soup-об'єкт сторінки та витягує всі новини у вигляді списку словників із ключами title, link, date, summary.
save_to_csv(data): приймає список новин та зберігає його в CSV-файлі (назва файлу – news.csv).
5. Додаткові вимоги:

Використовуйте виключення для обробки помилок (наприклад, якщо сторінка не завантажується, чи HTML-елементи не знайдені).
Переконайтеся, що всі дані зберігаються у структурованому форматі (наприклад, у CSV-файлі).

Очікуваний результат:
Запустіть скрипт, який завантажить сторінку новин, збере інформацію про останні новини та збереже її у форматі CSV.
Файл news.csv повинен містити стовпці title, link, date, summary з відповідними даними для кожної новини.
Додаткові завдання:
Фільтрація за датою: Додайте можливість фільтрувати новини за останні кілька днів (наприклад, новини за останні 7 днів).
Візуалізація: Використайте бібліотеку pandas для виведення короткого статистичного звіту (наприклад, скільки новин було опубліковано кожного дня).

Критерії оцінювання:
Правильне використання BeautifulSoup для навігації та пошуку HTML-елементів.
Здатність отримати необхідні дані (заголовок, дату, посилання, опис).
Коректне збереження інформації у CSV.
Відсутність помилок при виконанні коду та обробка виключень (помилок).
